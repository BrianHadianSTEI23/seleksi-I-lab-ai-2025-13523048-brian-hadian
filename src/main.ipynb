{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3cdcb44",
   "metadata": {},
   "source": [
    "# Bitcoin Price Range History 20250901\n",
    "\n",
    "This data is in format csv and has around 2 million rows. This dataset has columns as such\n",
    "\n",
    "1. Start : Date (Indicates the start date of the data record) (Format XX-XX-XXXX) (NUMERIC)\n",
    "\n",
    "2. End : Date ( Indicates the end date of the data record) (Format XX/XX/XXXX) (NUMERIC)\n",
    "\n",
    "3. Open : Number ( The price at which Bitcoin Ended trading at the beginning of the day.) (NUMERIC)\n",
    "\n",
    "4. High : Number (The highest price point reached by Bitcoin during the day.) (NUMERIC)\n",
    "\n",
    "5. Low : Number (The lowest price point reached by Bitcoin during the day.) (NUMERIC)\n",
    "\n",
    "6. Close : Number (The price at which Bitcoin ended trading at the close of the day.) (NUMERIC)\n",
    "\n",
    "7. Volume : Number (Total volume of Bitcoin traded during the day.) \n",
    "\n",
    "8. Market Cap : Number (The total market value of Bitcoin at the end of the day.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa7492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from reinforcement.sarsa import SARSAWumpus\n",
    "from reinforcement.qLearning import QLearningWumpus\n",
    "from supervisedLearning.ann import ArtificialNeuralNetwork\n",
    "from supervisedLearning.regressionTree import RegressionTree\n",
    "from supervisedLearning.knn import KNearestNeigbor\n",
    "from supervisedLearning.regression import PolynomialRegression\n",
    "from supervisedLearning.svm import SupportVectorMachine\n",
    "from unsupervisedLearning.dbscan import DBScan\n",
    "from unsupervisedLearning.kMeans import KMeans\n",
    "from unsupervisedLearning.pca import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a991edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "dataset1 = \"../data/bitcoin_2010-07-17_2024-06-28.csv\"\n",
    "dataset2 = \"../data/iris.csv\"\n",
    "\n",
    "df1 = pd.read_csv(dataset1)\n",
    "df2 = pd.read_csv(dataset2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3310894",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf4681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jumlah data\n",
    "print(df1.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a10143",
   "metadata": {},
   "source": [
    "## Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef5cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start\n",
    "print(pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\").dt.day.mean())\n",
    "print(pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\").dt.month.mean())\n",
    "print(pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\").dt.year.mean())\n",
    "\n",
    "#end \n",
    "print(pd.to_datetime(df1[\"End\"], format='%Y-%m-%d').dt.day.mean())\n",
    "print(pd.to_datetime(df1[\"End\"], format='%Y-%m-%d').dt.month.mean())\n",
    "print(pd.to_datetime(df1[\"End\"], format='%Y-%m-%d').dt.year.mean())\n",
    "\n",
    "# latitude\n",
    "print(df1[\"Open\"].mean())\n",
    "print(df1[\"High\"].mean())\n",
    "print(df1[\"Low\"].mean())\n",
    "print(df1[\"Close\"].mean())\n",
    "print(df1[\"Volume\"].mean())\n",
    "print(df1[\"Market Cap\"].mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df55937d",
   "metadata": {},
   "source": [
    "## Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad2e1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start\n",
    "print(pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\").dt.day.std())\n",
    "print(pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\").dt.month.std())\n",
    "print(pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\").dt.year.std())\n",
    "\n",
    "#end \n",
    "print(pd.to_datetime(df1[\"End\"], format='%Y-%m-%d').dt.day.std())\n",
    "print(pd.to_datetime(df1[\"End\"], format='%Y-%m-%d').dt.month.std())\n",
    "print(pd.to_datetime(df1[\"End\"], format='%Y-%m-%d').dt.year.std())\n",
    "\n",
    "# latitude\n",
    "print(df1[\"Open\"].std())\n",
    "print(df1[\"High\"].std())\n",
    "print(df1[\"Low\"].std())\n",
    "print(df1[\"Close\"].std())\n",
    "print(df1[\"Volume\"].std())\n",
    "print(df1[\"Market Cap\"].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41773959",
   "metadata": {},
   "source": [
    "## Minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e6c4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start\n",
    "print(pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\").dt.hour.min())\n",
    "print(pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\").dt.minute.min())\n",
    "print(pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\").dt.second.min())\n",
    "\n",
    "#end \n",
    "print(pd.to_datetime(df1[\"End\"], format='%Y-%m-%d').dt.date.min())\n",
    "print(pd.to_datetime(df1[\"End\"], format='%Y-%m-%d').dt.month.min())\n",
    "print(pd.to_datetime(df1[\"End\"], format='%Y-%m-%d').dt.year.min())\n",
    "\n",
    "# latitude\n",
    "print(df1[\"Open\"].min())\n",
    "print(df1[\"High\"].min())\n",
    "print(df1[\"Low\"].min())\n",
    "print(df1[\"Close\"].min())\n",
    "print(df1[\"Volume\"].min())\n",
    "print(df1[\"Market Cap\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeb52a2",
   "metadata": {},
   "source": [
    "## Maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6918939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start\n",
    "print(pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\").dt.hour.max())\n",
    "print(pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\").dt.minute.max())\n",
    "print(pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\").dt.second.max())\n",
    "\n",
    "#end \n",
    "print(pd.to_datetime(df1[\"End\"], format='%Y-%m-%d').dt.date.max())\n",
    "print(pd.to_datetime(df1[\"End\"], format='%Y-%m-%d').dt.month.max())\n",
    "print(pd.to_datetime(df1[\"End\"], format='%Y-%m-%d').dt.year.min())\n",
    "\n",
    "# latitude\n",
    "print(df1[\"Open\"].max())\n",
    "print(df1[\"High\"].max())\n",
    "print(df1[\"Low\"].max())\n",
    "print(df1[\"Close\"].max())\n",
    "print(df1[\"Volume\"].max())\n",
    "print(df1[\"Market Cap\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327bb9a8",
   "metadata": {},
   "source": [
    "## Quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba1d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start\n",
    "print(pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\").dt.hour.quantile([0.25, 0.5, 0.75]))\n",
    "print(pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\").dt.minute.quantile([0.25, 0.5, 0.75]))\n",
    "print(pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\").dt.second.quantile([0.25, 0.5, 0.75]))\n",
    "\n",
    "#end \n",
    "print(pd.to_datetime(df1[\"End\"], format='%Y-%m-%d').dt.date.quantile([0.25, 0.5, 0.75]))\n",
    "print(pd.to_datetime(df1[\"End\"], format='%Y-%m-%d').dt.month.quantile([0.25, 0.5, 0.75]))\n",
    "print(pd.to_datetime(df1[\"End\"], format='%Y-%m-%d').dt.year.quantile([0.25, 0.5, 0.75]))\n",
    "\n",
    "# latitude\n",
    "print(df1[\"Open\"].quantile([0.25, 0.5, 0.75]))\n",
    "print(df1[\"High\"].quantile([0.25, 0.5, 0.75]))\n",
    "print(df1[\"Low\"].quantile([0.25, 0.5, 0.75]))\n",
    "print(df1[\"Close\"].quantile([0.25, 0.5, 0.75]))\n",
    "print(df1[\"Volume\"].quantile([0.25, 0.5, 0.75]))\n",
    "print(df1[\"Market Cap\"].quantile([0.25, 0.5, 0.75]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70317e0",
   "metadata": {},
   "source": [
    "# Data distribution check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aec0cca",
   "metadata": {},
   "source": [
    "## Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f8cf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start\n",
    "sns.histplot(pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\",  errors=\"coerce\").dt.year, bins=24, kde=True)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot\n",
    "sns.boxplot(x=pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\",  errors=\"coerce\").dt.year)\n",
    "plt.show()\n",
    " \n",
    "# start\n",
    "sns.histplot(pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\",  errors=\"coerce\").dt.month, bins=24, kde=True)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot\n",
    "sns.boxplot(x=pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\",  errors=\"coerce\").dt.month)\n",
    "plt.show()\n",
    " \n",
    "# start\n",
    "sns.histplot(pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\",  errors=\"coerce\").dt.date, bins=24, kde=True)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot\n",
    "sns.boxplot(x=pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\",  errors=\"coerce\").dt.date)\n",
    "plt.show()\n",
    " \n",
    "# end\n",
    "sns.histplot(pd.to_datetime(df1[\"End\"], format=\"%Y-%m-%d\",  errors=\"coerce\").dt.year, bins=60, kde=True)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot\n",
    "sns.boxplot(x=pd.to_datetime(df1[\"End\"], format=\"%Y-%m-%d\", errors=\"coerce\").dt.year)\n",
    "plt.show()\n",
    "\n",
    "# end\n",
    "sns.histplot(pd.to_datetime(df1[\"End\"], format=\"%Y-%m-%d\",  errors=\"coerce\").dt.month, bins=60, kde=True)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot\n",
    "sns.boxplot(x=pd.to_datetime(df1[\"End\"], format=\"%Y-%m-%d\", errors=\"coerce\").dt.month)\n",
    "plt.show()\n",
    "\n",
    "# end\n",
    "sns.histplot(pd.to_datetime(df1[\"End\"], format=\"%Y-%m-%d\",  errors=\"coerce\").dt.date, bins=60, kde=True)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot\n",
    "sns.boxplot(x=pd.to_datetime(df1[\"End\"], format=\"%Y-%m-%d\", errors=\"coerce\").dt.date)\n",
    "plt.show()\n",
    "\n",
    "# open\n",
    "sns.histplot(df1[\"Open\"], bins=60, kde=True)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot\n",
    "sns.boxplot(x=df1[\"Open\"])\n",
    "plt.show()\n",
    "\n",
    "# open\n",
    "sns.histplot(df1[\"High\"], bins=60, kde=True)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot\n",
    "sns.boxplot(x=df1[\"High\"])\n",
    "plt.show()\n",
    "\n",
    "# open\n",
    "sns.histplot(df1[\"Low\"], bins=60, kde=True)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot\n",
    "sns.boxplot(x=df1[\"Low\"])\n",
    "plt.show()\n",
    "\n",
    "# open\n",
    "sns.histplot(df1[\"Close\"], bins=60, kde=True)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot\n",
    "sns.boxplot(x=df1[\"Close\"])\n",
    "plt.show()\n",
    "\n",
    "# open\n",
    "sns.histplot(df1[\"Volume\"], bins=60, kde=True)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot\n",
    "sns.boxplot(x=df1[\"Volume\"])\n",
    "plt.show()\n",
    "\n",
    "# open\n",
    "sns.histplot(df1[\"Market Cap\"], bins=60, kde=True)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot\n",
    "sns.boxplot(x=df1[\"Market Cap\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aa5c66",
   "metadata": {},
   "source": [
    "## Outlier Check (Z-value check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5e18df",
   "metadata": {},
   "source": [
    "## Numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b474e20",
   "metadata": {},
   "source": [
    "### Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c11c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Start column to datetime once\n",
    "df1[\"Start_dt\"] = pd.to_datetime(df1[\"Start\"], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "# --- Year outliers ---\n",
    "year = df1[\"Start_dt\"].dt.year\n",
    "mean_year = year.mean()\n",
    "std_year = year.std()\n",
    "z_score_year = (year - mean_year) / std_year\n",
    "outliers_year = df1[z_score_year.abs() > 3]\n",
    "print(f\"Year outliers count: {len(outliers_year)}\")\n",
    "\n",
    "# --- Month outliers ---\n",
    "month = df1[\"Start_dt\"].dt.month\n",
    "mean_month = month.mean()\n",
    "std_month = month.std()\n",
    "z_score_month = (month - mean_month) / std_month\n",
    "outliers_month = df1[z_score_month.abs() > 3]\n",
    "print(f\"Month outliers count: {len(outliers_month)}\")\n",
    "\n",
    "# --- Day outliers ---\n",
    "day = df1[\"Start_dt\"].dt.day\n",
    "mean_day = day.mean()\n",
    "std_day = day.std()\n",
    "z_score_day = (day - mean_day) / std_day\n",
    "outliers_day = df1[z_score_day.abs() > 3]\n",
    "print(f\"Day outliers count: {len(outliers_day)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16101014",
   "metadata": {},
   "source": [
    "### End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4214e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = pd.to_datetime(df1[\"End\"], format='%Y-%m-%d', errors='coerce').dt.year.mean()\n",
    "std = pd.to_datetime(df1[\"End\"], format='%Y-%m-%d', errors='coerce').dt.year.std()\n",
    "\n",
    "z_score = (pd.to_datetime(df1[\"End\"], format='%Y-%m-%d', errors='coerce').dt.year - mean) / std\n",
    "outliers = df1[z_score.abs() > 3]\n",
    "print(f\"Outliers count {len(outliers)}\")\n",
    "\n",
    "mean = pd.to_datetime(df1[\"End\"], format='%Y-%m-%d', errors='coerce').dt.month.mean()\n",
    "std = pd.to_datetime(df1[\"End\"], format='%Y-%m-%d', errors='coerce').dt.month.std()\n",
    "\n",
    "z_score = (pd.to_datetime(df1[\"End\"], format='%Y-%m-%d', errors='coerce').dt.month - mean) / std\n",
    "outliers = df1[z_score.abs() > 3]\n",
    "print(f\"Outliers count {len(outliers)}\")\n",
    "\n",
    "mean = pd.to_datetime(df1[\"End\"], format='%Y-%m-%d', errors='coerce').dt.day.mean()\n",
    "std = pd.to_datetime(df1[\"End\"], format='%Y-%m-%d', errors='coerce').dt.day.std()\n",
    "\n",
    "z_score = (pd.to_datetime(df1[\"End\"], format='%Y-%m-%d', errors='coerce').dt.day - mean) / std\n",
    "outliers = df1[z_score.abs() > 3]\n",
    "print(f\"Outliers count {len(outliers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec8db55",
   "metadata": {},
   "source": [
    "### Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f64e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df1[\"Open\"].mean()\n",
    "std = df1[\"Open\"].std()\n",
    "\n",
    "z_score = (df1[\"Open\"] - mean) / std\n",
    "outliers = df1[z_score.abs() > 3]\n",
    "print(f\"Outliers count {len(outliers)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd35a1a2",
   "metadata": {},
   "source": [
    "### High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ff065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df1[\"High\"].mean()\n",
    "std = df1[\"High\"].std()\n",
    "\n",
    "z_score = (df1[\"High\"] - mean) / std\n",
    "outliers = df1[z_score.abs() > 3]\n",
    "print(f\"Outliers count {len(outliers)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff787233",
   "metadata": {},
   "source": [
    "### Low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f11acd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df1[\"Low\"].mean()\n",
    "std = df1[\"Low\"].std()\n",
    "\n",
    "z_score = (df1[\"Low\"] - mean) / std\n",
    "outliers = df1[z_score.abs() > 3]\n",
    "print(f\"Outliers count {len(outliers)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25085486",
   "metadata": {},
   "source": [
    "### Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efc4335",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df1[\"Close\"].mean()\n",
    "std = df1[\"Close\"].std()\n",
    "\n",
    "z_score = (df1[\"Close\"] - mean) / std\n",
    "outliers = df1[z_score.abs() > 3]\n",
    "print(f\"Outliers count {len(outliers)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48331a32",
   "metadata": {},
   "source": [
    "### Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c9c678",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df1[\"Volume\"].mean()\n",
    "std = df1[\"Volume\"].std()\n",
    "\n",
    "z_score = (df1[\"Volume\"] - mean) / std\n",
    "outliers = df1[z_score.abs() > 3]\n",
    "print(f\"Outliers count {len(outliers)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dd1859",
   "metadata": {},
   "source": [
    "### Market Cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67c9ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df1[\"Market Cap\"].mean()\n",
    "std = df1[\"Market Cap\"].std()\n",
    "\n",
    "z_score = (df1[\"Market Cap\"] - mean) / std\n",
    "outliers = df1[z_score.abs() > 3]\n",
    "print(f\"Outliers count {len(outliers)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c283471",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "This stage include data cleaning (handling missing values, remove duplicates, correct error and inconsistencies), Data transformation (normalization, standardization, categorical data encoding) \n",
    "Feature selection, and Dimensionality reduction. Handling missing values will be approached in categorical values first. If null is found, then it will changed into modus of that certain feature. \n",
    "If outlier is found, it will removed from the dataset. In numerical values, every null value will be changed into the mean value of that feature related to that certain crime. If outlier is found,\n",
    "it will be removed from the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9511bf",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d6492c",
   "metadata": {},
   "source": [
    "### Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bfb932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all rows without the null values in very row\n",
    "year_mean = int(pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\", errors=\"coerce\").dt.year.mean())\n",
    "month_mean = int(pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\", errors=\"coerce\").dt.month.mean())\n",
    "date_mean = int(pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\", errors=\"coerce\").dt.day.mean())\n",
    "datetime_mean = f\"{month_mean:02d}-{date_mean:02d}-{year_mean:02d}\"\n",
    "df1.loc[df1[\"Start\"] == \"(null)\", \"Start\"] = datetime_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8df444",
   "metadata": {},
   "source": [
    "### End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b300f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_mean = int(pd.to_datetime(df1[\"End\"], format=\"%Y-%m-%d\", errors=\"coerce\").dt.year.mean())\n",
    "month_mean = int(pd.to_datetime(df1[\"End\"], format=\"%Y-%m-%d\", errors=\"coerce\").dt.month.mean())\n",
    "date_mean = int(pd.to_datetime(df1[\"End\"], format=\"%Y-%m-%d\", errors=\"coerce\").dt.day.mean())\n",
    "datetime_mean = f\"{month_mean:02d}-{date_mean:02d}-{year_mean:02d}\"\n",
    "df1.loc[df1[\"End\"] == \"(null)\", \"End\"] = datetime_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d38409",
   "metadata": {},
   "source": [
    "### Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b96f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df1[\"Open\"].mean()\n",
    "df1.loc[df1[\"Open\"] == \"(null)\", \"Open\"] = mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ead3e8",
   "metadata": {},
   "source": [
    "### High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1592db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df1[\"High\"].mean()\n",
    "df1.loc[df1[\"High\"] == \"(null)\", \"High\"] = mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33762d39",
   "metadata": {},
   "source": [
    "### Low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38590464",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df1[\"Low\"].mean()\n",
    "df1.loc[df1[\"Low\"] == \"(null)\", \"Low\"] = mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46d7058",
   "metadata": {},
   "source": [
    "### Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab0a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df1[\"Close\"].mean()\n",
    "df1.loc[df1[\"Close\"] == \"(null)\", \"Close\"] = mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8cef3e",
   "metadata": {},
   "source": [
    "### Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf7e63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df1[\"Volume\"].mean()\n",
    "df1.loc[df1[\"Volume\"] == \"(null)\", \"Volume\"] = mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4202019c",
   "metadata": {},
   "source": [
    "### Market cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6d498f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df1[\"Market Cap\"].mean()\n",
    "df1.loc[df1[\"Market Cap\"] == \"(null)\", \"Market Cap\"] = mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2601461",
   "metadata": {},
   "source": [
    "# Data Encoding\n",
    "Encoding is needed to be able to get the value computed by algorithms (KNN, and many algorithms that rely on doing it using numbers). In this case, it is only needed to convert the date in the Start column into continuous value (in second relative from year 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064775c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearToSecond = pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\", errors=\"coerce\").dt.year * 365 * 24 * 60 * 60\n",
    "monthToSecond = pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\", errors=\"coerce\").dt.month * 30 * 24 * 60 * 60\n",
    "dateToSecond = pd.to_datetime(df1[\"Start\"], format=\"%Y-%m-%d\", errors=\"coerce\").dt.day * 24 * 60 * 60\n",
    "df1[\"Start\"] = yearToSecond + monthToSecond + dateToSecond\n",
    "\n",
    "yearToSecond = pd.to_datetime(df1[\"End\"], format=\"%Y-%m-%d\", errors=\"coerce\").dt.year * 365 * 24 * 60 * 60\n",
    "monthToSecond = pd.to_datetime(df1[\"End\"], format=\"%Y-%m-%d\", errors=\"coerce\").dt.month * 30 * 24 * 60 * 60\n",
    "dateToSecond = pd.to_datetime(df1[\"End\"], format=\"%Y-%m-%d\", errors=\"coerce\").dt.day * 24 * 60 * 60\n",
    "df1[\"End\"] = yearToSecond + monthToSecond + dateToSecond"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f4ba3",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "Feature selection is done to get only the relevant column, that is the all of the column except the end date and for processing SVM, there will be a new column that will store the year and month in year-month format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49ec1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your Start column is in seconds since epoch\n",
    "df1[\"Start_dt\"] = pd.to_datetime(df1[\"Start\"], unit='s', errors='coerce')\n",
    "\n",
    "# If your Start column is in milliseconds since epoch\n",
    "# df1[\"Start_dt\"] = pd.to_datetime(df1[\"Start\"], unit='ms', errors='coerce')\n",
    "\n",
    "# Now you can extract Period\n",
    "df1[\"Period\"] = df1[\"Start_dt\"].dt.strftime(\"%Y-%m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283f7b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing feature and class of new column period\n",
    "features = [\"Open\", \"High\", \"Low\", \"Close\", \"Market Cap\", \"Volume\"]\n",
    "target = \"Start\"\n",
    "svmTarget = \"Period_encoded\"\n",
    "\n",
    "classes = df1[\"Period\"].unique()\n",
    "period_to_num = {p: i for i, p in enumerate(sorted(classes))}\n",
    "df1[\"Period_encoded\"] = df1[\"Period\"].map(period_to_num)\n",
    "\n",
    "# Prepare X and Y\n",
    "X = df1[features]\n",
    "Y = np.array(df1[\"Start\"], dtype=float)\n",
    "\n",
    "svmY = np.array(df1[svmTarget], dtype=float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d15113",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "Dimensionality reduction is done to reduce the noise of the characteristics of the attributes and\n",
    "focus on what causing and the pattern on which the event emerges. In this example, there is no need to do so because every value is in simple form and it is not intended to determine a new column that is significant to the particular target label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9559ad",
   "metadata": {},
   "source": [
    "## Balancing\n",
    "Based on the diagram in the EDA, there are a pattern of skewness of the data in the time context, but\n",
    "other than that, there is a nice variance (not to significant) such that the model that will generated from this dataset is perceived not be biased. Thus, it is not needed to be balanced with\n",
    "any other method (balancing methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ac2611",
   "metadata": {},
   "source": [
    "# Bagian 2 (Supervised Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef516e8",
   "metadata": {},
   "source": [
    "## K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c4b36d",
   "metadata": {},
   "source": [
    "#### Hold out validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ebc719",
   "metadata": {},
   "source": [
    "##### Implementasi Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3690e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition into 80% and 20% (testing)\n",
    "nTrain = int(0.8 * len(df1))\n",
    "trainData = df1.iloc[:nTrain][features]\n",
    "testData = df1.iloc[nTrain:][features]\n",
    "\n",
    "# init\n",
    "# \"Start\", \"Open\", \"High\", \"Low\", \"Close\", \"Market Cap\", \"Volume\", \"Period\"\n",
    "openVal = float(input())\n",
    "highVal = float(input())\n",
    "lowVal = float(input())\n",
    "closeVal = float(input())\n",
    "marketCapVal = float(input())\n",
    "volumeVal = float(input())\n",
    "\n",
    "distanceFunction = (input()) \n",
    "neighborCount = int(input())\n",
    "minkowskiExp = float(input())\n",
    "knn = KNearestNeigbor(distanceFunction, neighborCount, \"Start\", minkowskiExp)\n",
    "\n",
    "# predict\n",
    "x = np.array([openVal, highVal, lowVal, closeVal, marketCapVal, volumeVal])\n",
    "prediction = knn.predict(trainData, x)\n",
    "print(f\"Prediction : {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c3a04d",
   "metadata": {},
   "source": [
    "##### Implementasi Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528f92c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition into 80% and 20% (testing)\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# X = features (all columns except target)\n",
    "# y = target column\n",
    "X_train = trainData.drop(columns=[\"Start\"])\n",
    "y_train = trainData[\"Start\"]\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=neighborCount, metric='minkowski', p=minkowskiExp)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict for a new sample\n",
    "x_new = np.array([openVal, highVal, lowVal, closeVal, marketCapVal, volumeVal]).reshape(1, -1)\n",
    "predicted = knn.predict(x_new)\n",
    "print(\"Predicted value:\", predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf370b",
   "metadata": {},
   "source": [
    "#### K fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af038700",
   "metadata": {},
   "source": [
    "##### Implementasi Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fc2dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition into k = user input\n",
    "k = int(input())\n",
    "n = len(df1)\n",
    "fold_size = n // k\n",
    "\n",
    "for i in range(k) :\n",
    "    start_idx = i * fold_size\n",
    "    end_idx = (i + 1) * fold_size if i != k-1 else n  # last fold may include remainder\n",
    "    testData = df1.iloc[start_idx:end_idx][features]\n",
    "    \n",
    "    # Define train data by dropping test indices\n",
    "    trainData = df1.drop(df1.index[start_idx:end_idx])[features]\n",
    "\n",
    "    # init\n",
    "    # \"Open\", \"High\", \"Low\", \"Close\", \"Market Cap\", \"Volume\"\n",
    "    openVal = float(input())\n",
    "    highVal = float(input())\n",
    "    lowVal = float(input())\n",
    "    closeVal = float(input())\n",
    "    marketCapVal = float(input())\n",
    "    volumeVal = float(input()) # in miliseconds\n",
    "    \n",
    "    distanceFunction = (input()) \n",
    "    neighborCount = int(input())\n",
    "    minkowskiExp = float(input())\n",
    "    knn = KNearestNeigbor(distanceFunction, neighborCount, \"Start\", minkowskiExp)\n",
    "\n",
    "    # predict\n",
    "    x = np.array([openVal, highVal, lowVal, closeVal, marketCapVal, volumeVal])\n",
    "    prediction = knn.predict(trainData, x)\n",
    "\n",
    "    print(f\"Fold {i+1} Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eac08a",
   "metadata": {},
   "source": [
    "##### Implementasi Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee62dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# X = features (all columns except target)\n",
    "# y = target column\n",
    "\n",
    "# partition into k = user input\n",
    "k = int(input())\n",
    "n = len(df1)\n",
    "fold_size = n // k\n",
    "\n",
    "for i in range(k) :\n",
    "    start_idx = i * fold_size\n",
    "    end_idx = (i + 1) * fold_size if i != k-1 else n  # last fold may include remainder\n",
    "    testData = df1.iloc[start_idx:end_idx][features]\n",
    "    \n",
    "    # Define train data by dropping test indices\n",
    "    trainData = df1.drop(df1.index[start_idx:end_idx])[features]\n",
    "\n",
    "    X_train = trainData.drop(columns=[\"Start\"])\n",
    "    y_train = trainData[\"Start\"]\n",
    "\n",
    "    knn = KNeighborsRegressor(n_neighbors=neighborCount, metric='minkowski', p=minkowskiExp)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict for a new sample\n",
    "    x_new = np.array([openVal, highVal, lowVal, closeVal, marketCapVal, volumeVal]).reshape(1, -1)\n",
    "    predicted = knn.predict(x_new)\n",
    "    print(f\"Fold {i + 1} predicted value:\", predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e5c62c",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e3960a",
   "metadata": {},
   "source": [
    "#### Hold out validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ab7009",
   "metadata": {},
   "source": [
    "##### Implementasi Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cf0440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "nTrain = int(0.8 * len(df1))\n",
    "X_train = df1.iloc[:nTrain][features]\n",
    "X_test = df1.iloc[nTrain:][features]\n",
    "\n",
    "Y_train = np.array(df1.iloc[:nTrain][\"Start\"], dtype=float)\n",
    "Y_test = np.array(df1.iloc[nTrain:][\"Start\"], dtype=float)\n",
    "\n",
    "# Or for Period_encoded\n",
    "svmY_train = np.array(df1.iloc[:nTrain][\"Period_encoded\"], dtype=float)\n",
    "svmY_test = np.array(df1.iloc[nTrain:][\"Period_encoded\"], dtype=float)\n",
    "\n",
    "# Initialize model\n",
    "degree = 2\n",
    "learning_rate = 0.000001\n",
    "regularization = \"l2\"\n",
    "model = PolynomialRegression(\n",
    "    degree=degree,\n",
    "    learningRate=learning_rate,\n",
    "    regularizationTrem=regularization,\n",
    "    features=features,\n",
    "    iteration=5000\n",
    ")\n",
    "\n",
    "# Train model on continuous target (Start)\n",
    "model.train(X_train, Y_train)\n",
    "\n",
    "# Predict on test set\n",
    "predictions = np.array([model.predict(x.to_numpy()) for _, x in X_test.iterrows()])\n",
    "\n",
    "# Evaluate performance (MSE)\n",
    "mse = np.mean((predictions - Y_test) ** 2)\n",
    "print(\"Test MSE:\", mse)\n",
    "print(f\"prediction: {predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6642940c",
   "metadata": {},
   "source": [
    "##### Implementasi Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86172eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Inputs for new prediction\n",
    "openVal = float(input(\"Open: \"))\n",
    "highVal = float(input(\"High: \"))\n",
    "lowVal = float(input(\"Low: \"))\n",
    "closeVal = float(input(\"Close: \"))\n",
    "marketCapVal = float(input(\"Market Cap: \"))\n",
    "volumeVal = float(input(\"Volume: \"))\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # X = df1[features]\n",
    "\n",
    "# Hold-out split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train regressor\n",
    "reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"R2 score:\", r2)\n",
    "\n",
    "# Predict new input\n",
    "new_input = np.array([[openVal, highVal, lowVal, closeVal, marketCapVal, volumeVal]])\n",
    "new_input_scaled = scaler.transform(new_input)\n",
    "predicted_seconds = reg.predict(new_input_scaled)[0]\n",
    "\n",
    "# Convert seconds since year 0 to datetime\n",
    "predicted_date = pd.to_datetime(predicted_seconds, unit='s', origin='unix')  # origin can be 'unix' if seconds from 1970\n",
    "print(\"Predicted Start (date):\", predicted_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1100d7c",
   "metadata": {},
   "source": [
    "#### K fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8afd22",
   "metadata": {},
   "source": [
    "##### Implementasi Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d64472",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------\n",
    "# 1️⃣ Input features\n",
    "# ------------------------------\n",
    "features = [\"Open\", \"High\", \"Low\", \"Close\", \"Market Cap\", \"Volume\"]\n",
    "X = df1[features]\n",
    "Y = np.array(df1[\"Start\"], dtype=float)  # target in seconds\n",
    "\n",
    "# ------------------------------\n",
    "# 2️⃣ Define k-fold function\n",
    "# ------------------------------\n",
    "def k_fold_regression(model_class, X, Y, k=5, **model_kwargs):\n",
    "    n = len(X)\n",
    "    indices = np.arange(n)\n",
    "    np.random.shuffle(indices)\n",
    "    fold_size = n // k\n",
    "    all_predictions = np.zeros(n)\n",
    "\n",
    "    for fold in range(k):\n",
    "        start = fold * fold_size\n",
    "        end = start + fold_size if fold < k - 1 else n\n",
    "\n",
    "        val_idx = indices[start:end]\n",
    "        train_idx = np.setdiff1d(indices, val_idx)\n",
    "\n",
    "        X_train, y_train = X.iloc[train_idx], Y[train_idx]\n",
    "        X_val, y_val = X.iloc[val_idx], Y[val_idx]\n",
    "\n",
    "        # ------------------------------\n",
    "        # 3️⃣ Train model\n",
    "        # ------------------------------\n",
    "        model = model_class(**model_kwargs)\n",
    "        model.train(X_train, y_train)\n",
    "\n",
    "        # ------------------------------\n",
    "        # 4️⃣ Test on validation fold\n",
    "        # ------------------------------\n",
    "        y_pred = np.array([model.predict(row.to_numpy()) for _, row in X_val.iterrows()])\n",
    "        all_predictions[val_idx] = y_pred\n",
    "\n",
    "        print(f\"Fold {fold+1} MSE: {np.mean((y_val - y_pred) ** 2):.4f}\")\n",
    "\n",
    "    # Overall MSE\n",
    "    mse_total = np.mean((Y - all_predictions) ** 2)\n",
    "    print(f\"\\nOverall MSE: {mse_total:.4f}\")\n",
    "    return all_predictions\n",
    "\n",
    "# ------------------------------\n",
    "# 5️⃣ Train and evaluate with k-fold\n",
    "# ------------------------------\n",
    "degree = 2\n",
    "learning_rate = 0.000001\n",
    "regularization = \"l2\"\n",
    "iteration = 5000\n",
    "\n",
    "predictions = k_fold_regression(\n",
    "    model_class=PolynomialRegression,\n",
    "    X=X,\n",
    "    Y=Y,\n",
    "    k=5,\n",
    "    degree=degree,\n",
    "    learningRate=learning_rate,\n",
    "    regularizationTrem=regularization,\n",
    "    features=features,\n",
    "    iteration=iteration\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 6️⃣ Predict on new input\n",
    "# ------------------------------\n",
    "openVal = float(input(\"Open: \"))\n",
    "highVal = float(input(\"High: \"))\n",
    "lowVal = float(input(\"Low: \"))\n",
    "closeVal = float(input(\"Close: \"))\n",
    "marketCapVal = float(input(\"Market Cap: \"))\n",
    "volumeVal = float(input(\"Volume: \"))\n",
    "\n",
    "new_input = np.array([openVal, highVal, lowVal, closeVal, marketCapVal, volumeVal])\n",
    "model_final = PolynomialRegression(\n",
    "    degree=degree,\n",
    "    learningRate=learning_rate,\n",
    "    regularizationTrem=regularization,\n",
    "    features=features,\n",
    "    iteration=iteration\n",
    ")\n",
    "\n",
    "# Train on full dataset before predicting\n",
    "model_final.train(X, Y)\n",
    "\n",
    "predicted_seconds = model_final.predict(new_input)\n",
    "predicted_date = pd.Timestamp('0000-01-01') + pd.to_timedelta(predicted_seconds, unit='s')\n",
    "print(\"Predicted Start (date):\", predicted_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d37cd0d",
   "metadata": {},
   "source": [
    "##### Implementasi Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5446850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# partition into 80% and 20% (testing)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ------------------------------\n",
    "# 2️⃣ Generate polynomial features\n",
    "# ------------------------------\n",
    "degree = 2\n",
    "poly = PolynomialFeatures(degree=degree, include_bias=True)\n",
    "X_poly = poly.fit_transform(X_scaled)\n",
    "\n",
    "# ------------------------------\n",
    "# 3️⃣ K-Fold cross-validation\n",
    "# ------------------------------\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "mse_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_poly), 1):\n",
    "    X_train, X_val = X_poly[train_idx], X_poly[val_idx]\n",
    "    y_train, y_val = Y[train_idx], Y[val_idx]\n",
    "\n",
    "    # Train\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Test\n",
    "    y_pred = regressor.predict(X_val)\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    mse_scores.append(mse)\n",
    "    print(f\"Fold {fold} MSE: {mse:.4f}\")\n",
    "\n",
    "print(f\"\\nAverage MSE across {k} folds: {np.mean(mse_scores):.4f}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 4️⃣ Train on full data for final prediction\n",
    "# ------------------------------\n",
    "regressor.fit(X_poly, Y)\n",
    "\n",
    "# ------------------------------\n",
    "# 5️⃣ Predict new input\n",
    "# ------------------------------\n",
    "openVal = float(input(\"Open: \"))\n",
    "highVal = float(input(\"High: \"))\n",
    "lowVal = float(input(\"Low: \"))\n",
    "closeVal = float(input(\"Close: \"))\n",
    "marketCapVal = float(input(\"Market Cap: \"))\n",
    "volumeVal = float(input(\"Volume: \"))\n",
    "\n",
    "new_input = np.array([[openVal, highVal, lowVal, closeVal, marketCapVal, volumeVal]])\n",
    "new_input_scaled = scaler.transform(new_input)\n",
    "new_input_poly = poly.transform(new_input_scaled)\n",
    "\n",
    "predicted_seconds = regressor.predict(new_input_poly)[0]\n",
    "predicted_date = pd.Timestamp('0000-01-01') + pd.to_timedelta(predicted_seconds, unit='s')\n",
    "print(\"Predicted Start (date):\", predicted_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bbe7bf",
   "metadata": {},
   "source": [
    "## Regression Tree (CART)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ba3ddf",
   "metadata": {},
   "source": [
    "#### Hold out validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dad9b3b",
   "metadata": {},
   "source": [
    "##### Implementasi Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4472ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition into 80% and 20% (testing)\n",
    "\n",
    "n_train = int(0.8 * len(df1))\n",
    "train_df = df1.iloc[:n_train]\n",
    "test_df = df1.iloc[n_train:]\n",
    "\n",
    "# Set hyperparameters\n",
    "maxDepth = 5      # max depth of the tree\n",
    "minSample = 5     # minimum samples per node\n",
    "maxVariance = 0.05  # minimum variance reduction to continue splitting\n",
    "\n",
    "# Initialize tree\n",
    "tree = RegressionTree(features=features, maxDepth=5, minSample=5, maxVariance=0.05)\n",
    "\n",
    "# Train\n",
    "tree.root = tree.train(train_df[features + [target]])\n",
    "\n",
    "predictions = []\n",
    "for _, row in test_df.iterrows():\n",
    "    x = row[features].to_dict()\n",
    "    pred = tree.predict(x)\n",
    "    predictions.append(pred)\n",
    "\n",
    "y_true = test_df[target].to_numpy()\n",
    "y_pred = np.array(predictions)\n",
    "\n",
    "# Evaluate\n",
    "mse = np.mean((y_true - y_pred) ** 2)\n",
    "print(\"MSE on test set:\", mse)\n",
    "\n",
    "new_input = {\n",
    "    \"Open\": 1000,\n",
    "    \"High\": 1020,\n",
    "    \"Low\": 990,\n",
    "    \"Close\": 1010,\n",
    "    \"Market Cap\": 5000000,\n",
    "    \"Volume\": 100000\n",
    "}\n",
    "\n",
    "predicted_seconds = tree.predict(new_input)\n",
    "predicted_date = pd.Timestamp('0000-01-01') + pd.to_timedelta(predicted_seconds, unit='s')\n",
    "print(\"Predicted Start (date):\", predicted_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89717739",
   "metadata": {},
   "source": [
    "##### Implementasi Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5395c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "features = [\"Open\", \"High\", \"Low\", \"Close\", \"Market Cap\", \"Volume\"]\n",
    "target = \"Start\"  # continuous target\n",
    "X = df1[features]\n",
    "y = df1[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "# Initialize DecisionTreeRegressor\n",
    "tree = DecisionTreeRegressor(\n",
    "    max_depth=5,      # max depth of the tree\n",
    "    min_samples_split=5,  # minimum samples per node\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train on the training set\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "# Compute MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE on test set:\", mse)\n",
    "\n",
    "new_input = pd.DataFrame([{\n",
    "    \"Open\": 1000,\n",
    "    \"High\": 1020,\n",
    "    \"Low\": 990,\n",
    "    \"Close\": 1010,\n",
    "    \"Market Cap\": 5000000,\n",
    "    \"Volume\": 100000\n",
    "}])\n",
    "\n",
    "predicted_seconds = tree.predict(new_input)[0]\n",
    "\n",
    "# Convert seconds to datetime\n",
    "predicted_date = pd.Timestamp('0000-01-01') + pd.to_timedelta(predicted_seconds, unit='s')\n",
    "print(\"Predicted Start (date):\", predicted_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10baf95",
   "metadata": {},
   "source": [
    "#### K fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd845fd4",
   "metadata": {},
   "source": [
    "##### Implementasi Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eb5a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def k_fold_cv(tree_class, df: pd.DataFrame, features: list[str], target: str, k: int = 5):\n",
    "    # Shuffle the dataset\n",
    "    df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    fold_size = len(df) // k\n",
    "    mses = []\n",
    "\n",
    "    for i in range(k):\n",
    "        # Define test and train indices\n",
    "        start = i * fold_size\n",
    "        end = start + fold_size if i < k - 1 else len(df)\n",
    "        test_df = df_shuffled.iloc[start:end]\n",
    "        train_df = pd.concat([df_shuffled.iloc[:start], df_shuffled.iloc[end:]], axis=0)\n",
    "\n",
    "        # Initialize and train tree\n",
    "        tree = tree_class(features=features, maxDepth=5, minSample=5, maxVariance=0.05)\n",
    "        tree.root = tree.train(train_df[features + [target]])\n",
    "\n",
    "        # Predict on test set\n",
    "        predictions = []\n",
    "        for _, row in test_df.iterrows():\n",
    "            x = row[features].to_dict()\n",
    "            pred = tree.predict(x)\n",
    "            predictions.append(pred)\n",
    "\n",
    "        y_true = test_df[target].to_numpy()\n",
    "        y_pred = np.array(predictions)\n",
    "        mse = np.mean((y_true - y_pred) ** 2)\n",
    "        mses.append(mse)\n",
    "\n",
    "        print(f\"Fold {i+1}: MSE = {mse}\")\n",
    "\n",
    "    avg_mse = np.mean(mses)\n",
    "    print(f\"Average MSE over {k} folds: {avg_mse}\")\n",
    "    return avg_mse\n",
    "\n",
    "features = [\"Open\", \"High\", \"Low\", \"Close\", \"Market Cap\", \"Volume\"]\n",
    "target = \"Start\"\n",
    "\n",
    "avg_mse = k_fold_cv(RegressionTree, df1, features, target, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626ffba1",
   "metadata": {},
   "source": [
    "##### Implementasi Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddf8941",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "features = [\"Open\", \"High\", \"Low\", \"Close\", \"Market Cap\", \"Volume\"]\n",
    "target = \"Start\"\n",
    "\n",
    "X = df1[features].to_numpy()\n",
    "y = df1[target].to_numpy()\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold CV\n",
    "mses = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Initialize and train DecisionTreeRegressor\n",
    "    tree = DecisionTreeRegressor(\n",
    "        max_depth=5,\n",
    "        min_samples_split=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    tree.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and compute MSE\n",
    "    y_pred = tree.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mses.append(mse)\n",
    "\n",
    "    print(f\"Fold {fold + 1}: MSE = {mse}\")\n",
    "\n",
    "avg_mse = np.mean(mses)\n",
    "print(f\"Average MSE over {kf.get_n_splits()} folds: {avg_mse}\")\n",
    "\n",
    "\n",
    "new_input = pd.DataFrame([{\n",
    "    \"Open\": 1000,\n",
    "    \"High\": 1020,\n",
    "    \"Low\": 990,\n",
    "    \"Close\": 1010,\n",
    "    \"Market Cap\": 5000000,\n",
    "    \"Volume\": 100000\n",
    "}])\n",
    "\n",
    "# Train on full dataset to make final prediction\n",
    "final_tree = DecisionTreeRegressor(max_depth=5, min_samples_split=5, random_state=42)\n",
    "final_tree.fit(X, y)\n",
    "predicted_seconds = final_tree.predict(new_input)[0]\n",
    "\n",
    "# Convert seconds to datetime\n",
    "predicted_date = pd.Timestamp('0000-01-01') + pd.to_timedelta(predicted_seconds, unit='s')\n",
    "print(\"Predicted Start (date):\", predicted_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec66b39c",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d4c47",
   "metadata": {},
   "source": [
    "#### Hold out validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4674f0c9",
   "metadata": {},
   "source": [
    "##### Implementasi Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd995bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition into 80% and 20% (testing)\n",
    "features = [\"Open\", \"High\", \"Low\", \"Close\", \"Market Cap\", \"Volume\"]\n",
    "targetSVM = \"Period\"  # your target column\n",
    "\n",
    "X = df1[features]\n",
    "y = df1[targetSVM]\n",
    "\n",
    "nTrain = int(0.8 * len(df1))\n",
    "\n",
    "trainData = df1.iloc[:nTrain]\n",
    "testData = df1.iloc[nTrain:]\n",
    "\n",
    "svm = SupportVectorMachine(\n",
    "    dataset=trainData,\n",
    "    target=targetSVM,\n",
    "    alpha=1.0,\n",
    "    learningRate=0.001,\n",
    "    regularizationTerm=\"l2\",\n",
    "    n=10000  # number of iterations\n",
    ")\n",
    "\n",
    "# Train the SVM on the training set\n",
    "svm.train()\n",
    "\n",
    "predictions = []\n",
    "for i in range(len(testData)):\n",
    "    x_row = testData.iloc[i]\n",
    "    pred = svm.predict(x_row)\n",
    "    predictions.append(pred)\n",
    "\n",
    "# Add predictions to the test dataframe\n",
    "testData[\"Predicted\"] = predictions\n",
    "\n",
    "accuracy = np.mean(testData[\"Predicted\"] == testData[targetSVM])\n",
    "print(\"Hold-out accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d2d12b",
   "metadata": {},
   "source": [
    "##### Implementasi Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a20d01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "features = [\"Open\", \"High\", \"Low\", \"Close\", \"Market Cap\", \"Volume\"]\n",
    "target = \"Period\"\n",
    "\n",
    "X = df1[features]\n",
    "y = df1[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Use a C-SVM with RBF kernel (you can also use 'linear' or 'poly')\n",
    "svm_clf = SVC(kernel='rbf', C=1.0, gamma='scale', decision_function_shape='ovr', random_state=42)\n",
    "svm_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = svm_clf.predict(X_test_scaled)\n",
    "\n",
    "print(\"Hold-out Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Example new input\n",
    "openVal = float(input())\n",
    "highVal = float(input())\n",
    "lowVal = float(input())\n",
    "closeVal = float(input())\n",
    "marketCapVal = float(input())\n",
    "volumeVal = float(input())\n",
    "new_input = np.array([[openVal, highVal, lowVal, closeVal, marketCapVal, volumeVal]])  # replace with real values\n",
    "new_input_scaled = scaler.transform(new_input)\n",
    "\n",
    "predicted_period = svm_clf.predict(new_input_scaled)\n",
    "print(\"Predicted Period:\", predicted_period[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17322cbb",
   "metadata": {},
   "source": [
    "#### K fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75248de7",
   "metadata": {},
   "source": [
    "##### Implementasi Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595e892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def k_fold_manual_svm(dataset: pd.DataFrame, target: str, k: int = 5, alpha=1.0, learningRate=0.001, regularizationTerm=\"l2\", n=10000):\n",
    "    dataset = dataset.sample(frac=1, random_state=42).reset_index(drop=True)  # shuffle\n",
    "    fold_size = len(dataset) // k\n",
    "    accuracies = []\n",
    "\n",
    "    for fold in range(k):\n",
    "        start = fold * fold_size\n",
    "        end = start + fold_size if fold != k-1 else len(dataset)\n",
    "        test_df = dataset.iloc[start:end]\n",
    "        train_df = pd.concat([dataset.iloc[:start], dataset.iloc[end:]]).reset_index(drop=True)\n",
    "\n",
    "        # Initialize and train SVM\n",
    "        svm = SupportVectorMachine(\n",
    "            dataset=train_df,\n",
    "            target=target,\n",
    "            alpha=alpha,\n",
    "            learningRate=learningRate,\n",
    "            regularizationTerm=regularizationTerm,\n",
    "            n=n\n",
    "        )\n",
    "        svm.train()\n",
    "\n",
    "        # Predict on test fold\n",
    "        correct = 0\n",
    "        for i in range(len(test_df)):\n",
    "            x_row = test_df.iloc[i]\n",
    "            pred = svm.predict(x_row)\n",
    "            if pred == x_row[target]:\n",
    "                correct += 1\n",
    "\n",
    "        accuracy = correct / len(test_df)\n",
    "        accuracies.append(accuracy)\n",
    "        print(f\"Fold {fold+1}: Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "    print(f\"\\nAverage Accuracy over {k}-folds: {np.mean(accuracies):.4f}\")\n",
    "\n",
    "features = [\"Open\", \"High\", \"Low\", \"Close\", \"Market Cap\", \"Volume\"]\n",
    "targetSVM = \"Period\"\n",
    "\n",
    "k_fold_manual_svm(df1, targetSVM, k=5, alpha=1.0, learningRate=0.001, regularizationTerm=\"l2\", n=10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35f4543",
   "metadata": {},
   "source": [
    "##### Implementasi Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3fe5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "features = [\"Open\", \"High\", \"Low\", \"Close\", \"Market Cap\", \"Volume\"]\n",
    "target = \"Period\"\n",
    "\n",
    "X = df1[features]\n",
    "y = df1[target]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "k = 5  # number of folds\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "svm_clf = SVC(kernel='rbf', C=1.0, gamma='scale', decision_function_shape='ovr', random_state=42)\n",
    "\n",
    "scores = cross_val_score(svm_clf, X_scaled, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "for i, score in enumerate(scores):\n",
    "    print(f\"Fold {i+1}: Accuracy = {score:.4f}\")\n",
    "\n",
    "print(f\"\\nAverage Accuracy over {k} folds: {np.mean(scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c18d76b",
   "metadata": {},
   "source": [
    "## Artificial Neural Network (ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae997a4c",
   "metadata": {},
   "source": [
    "#### Hold out validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79090675",
   "metadata": {},
   "source": [
    "##### Implementasi Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf43d7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition into 80% and 20% (testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85478a65",
   "metadata": {},
   "source": [
    "##### Implementasi Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb57c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition into 80% and 20% (testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3292360d",
   "metadata": {},
   "source": [
    "#### K fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b640f1",
   "metadata": {},
   "source": [
    "##### Implementasi Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8bf0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition into 80% and 20% (testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e09cdb",
   "metadata": {},
   "source": [
    "##### Implementasi Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872b9615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition into 80% and 20% (testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ae060a",
   "metadata": {},
   "source": [
    "# Bagian 3 (Unsupervised Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae406b0",
   "metadata": {},
   "source": [
    "Bagian ini akan menggunakan data iris.csv yang terletak pada folder data dengan kolom sebagai berikut: \n",
    "1. sepal_width : numerical\n",
    "2. sepal_length : numerical\n",
    "3. petal_width : numerical\n",
    "4. petal_length : numerical\n",
    "5. class : categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e14f301",
   "metadata": {},
   "source": [
    "## K Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b993f60",
   "metadata": {},
   "source": [
    "### Implementasi manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d058d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c023c7e7",
   "metadata": {},
   "source": [
    "### Implementasi Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5d570c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5973338d",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a6117c",
   "metadata": {},
   "source": [
    "### Implementasi manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f3e076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "603952e6",
   "metadata": {},
   "source": [
    "### Implementasi Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0336d055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c83a492e",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbee384d",
   "metadata": {},
   "source": [
    "### Implementasi manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fda6a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70a5f624",
   "metadata": {},
   "source": [
    "### Implementasi Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89fdec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
